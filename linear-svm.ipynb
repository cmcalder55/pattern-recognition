{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUnDhHD7kOoIk0yhsgXSrw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Immig4bS4-Hl"},"outputs":[],"source":["\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import svm\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import roc_curve, auc,precision_recall_curve\n","from sklearn.metrics import classification_report\n","from matplotlib import pyplot as plt\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.metrics import roc_auc_score\n","\n","\n"]},{"cell_type":"code","source":["\n","#load data\n","data=pd.read_csv(\"detect.csv\")\n","\n","# separate into train and test\n","x_train, x_test, y_train, y_test = train_test_split(\\\n","                data[\"text\"], data[\"label\"], test_size=0.3, random_state=0)\n","\n"],"metadata":{"id":"DrJl0P2P5Cug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def show_plots(params):\n","    plt.figure().set_figwidth(5);\n","    plt.plot(params[\"x\"], params[\"y\"], color='darkorange', lw=2);\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--');\n","    plt.xlim([0.0, 1.0]);\n","    plt.ylim([0.0, 1.05]);\n","\n","    if params[\"curve\"] == 'auc':\n","        plt.xlabel('False Positive Rate');\n","        plt.ylabel('True Positive Rate');\n","\n","    if params[\"curve\"] == 'prc':\n","        plt.xlabel('Recall');\n","        plt.ylabel('Precision');\n","\n","    plt.title(params[\"title\"]);\n","    plt.show();\n","\n","def create_model(x_train, y_train, x_test, y_test, min_df=1, stop_words=None,\n","                 print_result=True, algorithm_para=1.0):\n","\n","    # initialize the TfidfVectorizer without any parameters\n","    vec = TfidfVectorizer(stop_words=stop_words, min_df=min_df)\n","\n","    # choose classification model and add hyperparams\n","    model, model_name = svm.LinearSVC(C=algorithm_para), 'Linear SVM Model'\n","\n","    # fit vectorizer using x_train and vectorize training data\n","    x_train = vec.fit_transform(x_train)\n","    x_test = vec.transform(x_test)\n","    # fit classifier model with training data\n","    model.fit(x_train, y_train)\n","\n","    # predict test set output and get probability of guessing each class\n","    bin_preds = model.predict(x_test)\n","    pred_scores = model.decision_function(x_test)\n","\n","    # get ROC curve using tpr/fpr and calculate AUC score\n","    fpr, tpr, _ = roc_curve(y_test, pred_scores)\n","    auc_score = roc_auc_score(y_test, pred_scores)\n","\n","    # get PRC curve using precision/recall and calculate PRC score\n","    precision, recall, _ = precision_recall_curve(y_test, pred_scores)\n","    prc_score = auc(recall, precision)\n","\n","    if print_result:\n","        # print curve scores\n","        print(' AUC:{:.2%}\\n'.format(auc_score),'PRC:{:.2%}\\n'.format(prc_score))\n","        # print classification report\n","        print( classification_report(y_test, bin_preds, target_names=['0','1']) )\n","        # show curve plots\n","        show_plots({'x':fpr,\n","                    'y':tpr,\n","                    'curve':'auc',\n","                    'title': 'AUC of '+ model_name})\n","        show_plots({'x':recall,\n","                    'y':precision,\n","                    'curve':'prc',\n","                    'title': 'PRC of '+ model_name})\n","\n","    return auc_score, prc_score\n","\n","def search_para(docs, y):\n","\n","    # separate into train and test\n","    x_train, _, y_train, _ = train_test_split(\\\n","                docs, y, test_size=0.3, random_state=0)\n","\n","    metric = 'f1_macro'\n","    # initialize search params\n","    params = {\n","    'tfidf__stop_words': [None, 'english'],\n","    'tfidf__min_df': [1,2,5],\n","    'clf__C': [0.1,0.5,1]\n","    }\n","    # create pipeline with vectorizer and classifier\n","    pipeline = pipeline = Pipeline([\n","                                     (\"tfidf\", TfidfVectorizer()),\n","                                     (\"clf\", svm.LinearSVC())\n","                                   ])\n","\n","    grid = GridSearchCV(pipeline, param_grid=params, scoring = metric , cv=5, n_jobs = -1)\n","    # return optimal params\n","    return grid.fit(x_train,y_train)\n","\n","# Show the impact of sample size\n","def sample_size_impact(docs, y):\n","\n","    train_size = list(range(1,10))\n","    train_size.reverse()\n","    train_size = [i/10 for i in train_size]\n","\n","    performance = []\n","\n","    print_r = False\n","    for size in train_size:\n","        # if show results, print sample size\n","        if print_r == True:\n","            print('Training sample size: ',(10-size*10)/10)\n","\n","        # separate into train and test\n","        x_train, x_test, y_train, y_test = train_test_split(\n","                                                    docs, y,  test_size= size, random_state=0)\n","\n","        # choose whether to print result or not\n","        auc, _ = create_model(x_train, y_train, x_test, y_test, min_df = 1,\n","                            stop_words='english', print_result=print_r, algorithm_para=1.0)\n","\n","        performance.append(auc)\n","\n","\n","    plt.figure().set_figwidth(5);\n","    plt.plot(train_size, performance, color='navy', lw=2, label = 'Model Performance');\n","    plt.axis([1,0, 0.8, 1]);\n","    plt.xlabel('testing sample percentage');\n","    plt.ylabel('AUC');\n","    plt.legend();\n","    plt.show();\n"],"metadata":{"id":"M4v8BgfX5Em1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# default tokenizer\n","auc_score, prc_score = create_model(x_train, y_train, x_test, y_test, min_df = 1, stop_words=None,\n","                                    print_result=True, algorithm_para=1.0)\n"],"metadata":{"id":"VsnFCOSu5mHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# custom tokenizer\n","auc_score, prc_score = create_model(x_train, y_train, x_test, y_test, min_df = 1, stop_words='english',\n","                                    print_result=True, algorithm_para=1.0)\n"],"metadata":{"id":"ADnl_7945n5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","grid = search_para(data[\"text\"], data[\"label\"])\n","\n","for param_name in grid.best_params_:\n","    print(\"{0}:\\t{1}\".format(param_name,grid.best_params_[param_name]))\n","\n","print(\"best f1 score: {:.3f}\".format(grid.best_score_))\n","\n","min_df = grid.best_params_['tfidf__min_df']\n","stop_words = grid.best_params_['tfidf__stop_words']\n","C = grid.best_params_['clf__C']\n","\n","auc_score, prc_score = create_model(x_train, y_train, x_test, y_test, min_df=min_df, stop_words=stop_words,\n","                                    print_result=True, algorithm_para=C)\n","\n"],"metadata":{"id":"SCPkKltc6EWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","sample_size_impact(data[\"text\"], data[\"label\"])\n"],"metadata":{"id":"oqhSs8n-7Wy6"},"execution_count":null,"outputs":[]}]}