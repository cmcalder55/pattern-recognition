{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfowBnLomk7Lb7PSoD78+V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XABbkd8K3ghf"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import svm\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import roc_curve, auc,precision_recall_curve\n","from sklearn.metrics import classification_report\n","from matplotlib import pyplot as plt\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.metrics import roc_auc_score\n","\n"]},{"cell_type":"code","source":["\n","#load data\n","data=pd.read_csv(\"detect.csv\")\n","\n","# separate into train and test\n","x_train, x_test, y_train, y_test = train_test_split(\\\n","                data[\"text\"], data[\"label\"], test_size=0.3, random_state=0)\n","\n"],"metadata":{"id":"1ycWsQIO4lIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","def show_plots(params):\n","    plt.figure().set_figwidth(5);\n","    plt.plot(params[\"x\"], params[\"y\"], color='darkorange', lw=2);\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--');\n","    plt.xlim([0.0, 1.0]);\n","    plt.ylim([0.0, 1.05]);\n","\n","    if params[\"curve\"] == 'auc':\n","        plt.xlabel('False Positive Rate');\n","        plt.ylabel('True Positive Rate');\n","\n","    if params[\"curve\"] == 'prc':\n","        plt.xlabel('Recall');\n","        plt.ylabel('Precision');\n","\n","    plt.title(params[\"title\"]);\n","    plt.show();\n","\n","\n","def create_model(x_train, y_train, x_test, y_test, min_df = 1,stop_words=None,\n","                 print_result = True, algorithm_para=1.0):\n","\n","    # initialize the TfidfVectorizer without any parameters\n","    vec = TfidfVectorizer(stop_words=stop_words, min_df=min_df)\n","\n","    # choose classification model and add hyperparams\n","    model, model_name = MultinomialNB(alpha=algorithm_para), 'Naive-Bayes Model'\n","\n","    # fit vectorizer using x_train and vectorize training data\n","    x_train = vec.fit_transform(x_train)\n","    x_test = vec.transform(x_test)\n","    # fit classifier model with training data\n","    model.fit(x_train, y_train)\n","\n","    # get classification probs and choose \"1\" class\n","    pred_scores = model.predict_proba(x_test)[:,1]\n","    # convert to binary output based on confidence score\n","    bin_preds = np.where(pred_scores>0.5, 1, 0)\n","\n","    # get ROC curve using tpr/fpr and calculate AUC score\n","    fpr, tpr, _ = roc_curve(y_test, pred_scores)\n","    auc_score = roc_auc_score(y_test, pred_scores)\n","\n","    # get PRC curve using precision/recall and calculate PRC score\n","    precision, recall, _ = precision_recall_curve(y_test, pred_scores)\n","    prc_score = auc(recall, precision)\n","\n","    if print_result:\n","        # print curve scores\n","        print(' AUC:{:.2%}\\n'.format(auc_score),'PRC:{:.2%}\\n'.format(prc_score))\n","        # print classification report\n","        print( classification_report(y_test, bin_preds, target_names=['0','1']) )\n","        # show curve plots\n","        show_plots({'x':fpr,\n","                    'y':tpr,\n","                    'curve':'auc',\n","                    'title': 'AUC of '+ model_name})\n","        show_plots({'x':recall,\n","                    'y':precision,\n","                    'curve':'prc',\n","                    'title': 'PRC of '+ model_name})\n","\n","    return auc_score, prc_score\n","\n","# Show the impact of sample size\n","def sample_size_impact(docs, y):\n","\n","    train_size = list(range(1,10))\n","    train_size.reverse()\n","    train_size = [i/10 for i in train_size]\n","\n","    performance = []\n","\n","    print_r = False\n","    for size in train_size:\n","        # if show results, print sample size\n","        if print_r == True:\n","            print('Training sample size: ',(10-size*10)/10)\n","\n","        # separate into train and test\n","        x_train, x_test, y_train, y_test = train_test_split(\n","                                                    docs, y,  test_size= size, random_state=0)\n","\n","        # choose whether to print result or not\n","        auc, _ = create_model(x_train, y_train, x_test, y_test, min_df = 1,\n","                            stop_words='english', print_result=print_r, algorithm_para=1.0)\n","\n","        performance.append(auc)\n","\n","\n","    plt.figure().set_figwidth(5);\n","    plt.plot(train_size, performance, color='navy', lw=2, label = 'Model Performance');\n","    plt.axis([1,0, 0.8, 1]);\n","    plt.xlabel('testing sample percentage');\n","    plt.ylabel('AUC');\n","    plt.legend();\n","    plt.show();\n",""],"metadata":{"id":"3TdmTRPt4oIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# default tokenizer\n","auc_score, prc_score = create_model(x_train, y_train, x_test, y_test, \\\n","            model_type='nb',  min_df = 1, stop_words=None, \\\n","                                    print_result=True, algorithm_para=1.0)\n","\n"],"metadata":{"id":"VpXT2Cnk4u09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# custom tokenizer\n","auc_score, prc_score = create_model(x_train, y_train, x_test, y_test, \\\n","            model_type='nb',  min_df = 1, stop_words='english', \\\n","                                    print_result=True, algorithm_para=1.0)\n","\n"],"metadata":{"id":"VW-luC0l4xF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","sample_size_impact(data[\"text\"], data[\"label\"])\n"],"metadata":{"id":"WHN5p-zd7bmA"},"execution_count":null,"outputs":[]}]}